#!/usr/bin/env python
# -*-coding:utf-8 -*-
import concurrent.futures
import logging
import os
import re
import shutil
import subprocess
import threading
import time

import scrapy
from scrapy.exceptions import DropItem
from scrapy.pipelines.images import ImagesPipeline
from scrapy.utils.project import get_project_settings

from .utils.logger_config import PipelineLoggerMixin


class ImgPipeline(PipelineLoggerMixin, ImagesPipeline):

    def __init__(self, store_uri, download_func=None, settings=None):
        super(ImgPipeline, self).__init__(store_uri, download_func, settings)
        # è®¾ç½®pipelineä¸“å±æ—¥å¿—
        self.setup_pipeline_logger('img')

    def get_media_requests(self, item, info):
        # è·å–å°†ç”¨äºå­˜å‚¨å›¾ç‰‡çš„ç›®å½•è·¯å¾„
        dir_path = self.get_directory_path(item)
        self.log(f"Checking if directory exists at: {dir_path}")
        if not os.path.exists(dir_path):
            self.log(f"Directory does not exist, downloading images")
            for index, image_url in enumerate(item['image_urls']):
                yield scrapy.Request(image_url, meta={'item': item, 'index': index})
        else:
            self.log(f"Directory already exists, skipping download for images in: {dir_path}")

    def item_completed(self, results, item, info):
        image_paths = [x['path'] for ok, x in results if ok]
        if not image_paths:
            self.log(f"No images downloaded {image_paths}", logging.WARNING)
            raise DropItem(f"No images downloaded {image_paths}")
        item['image_paths'] = image_paths
        # æ‰“å°å®Œç»“çš„æ—¥å¿—
        self.log(f"Download images completed: {item['title']}")

        return item

    def file_path(self, request, response=None, info=None):
        item = request.meta['item']
        index = request.meta['index']
        url = request.url
        # è·å–å›¾ç‰‡æ ¼å¼
        image_format = url.split('.')[-1]
        file_name = f"{item['title']}-{index + 1}"  # ä»¥å›¾ç‰‡URLçš„é¡ºåºå‘½å
        # ç¡®ä¿å­—ç¬¦åˆæ³•ç”¨äºæ–‡ä»¶å
        file_name = self.sanitize_filename(file_name)
        self.log(f"Storing image at: {file_name}.{image_format}")
        return f"{item['site']}/{file_name}.{image_format}"

    def get_directory_path(self, item):
        # åŸºäºitemçš„'title'æ„å»ºå›¾ç‰‡å­˜å‚¨ç›®å½•è·¯å¾„
        settings = get_project_settings()
        images_store = settings.get('IMAGES_STORE')
        sanitized_title = self.sanitize_filename(item['title'])
        return os.path.join(images_store, item['site'], sanitized_title)

    def sanitize_filename(self, filename):
        """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤æˆ–æ›¿æ¢ä¸ç¬¦åˆè¦æ±‚çš„å­—ç¬¦."""
        # ç§»é™¤/æ›¿æ¢æ–‡ä»¶åä¸­ä¸åˆæ³•çš„å­—ç¬¦
        sanitized_name = re.sub(r'[\\/*?:"<>|\s]', '_', filename)
        # é™åˆ¶æ–‡ä»¶åé•¿åº¦
        if len(sanitized_name) > 100:
            sanitized_name = sanitized_name[:100]
        return sanitized_name


class M3U8Pipeline(PipelineLoggerMixin):
    """
    ç²¾ç®€ç‰ˆM3U8è§†é¢‘ä¸‹è½½ç®¡é“ï¼Œæ”¯æŒï¼š
    1. å¤šçº¿ç¨‹ä¸‹è½½
    2. ä¸´æ—¶æ–‡ä»¶ç®¡ç†  
    3. ä¸‹è½½å‰æ£€æŸ¥æ˜¯å¦å·²ä¸‹è½½
    4. ä¸‹è½½å®Œæˆåè®°å½•åˆ° m3u8_urls.txt
    5. å®æ—¶ä¸‹è½½è¿›åº¦ç›‘æ§
    """

    def __init__(self):
        # è®¾ç½®pipelineä¸“å±æ—¥å¿—
        self.setup_pipeline_logger('m3u8')

        self.settings = get_project_settings()
        self.videos_store = self.settings.get('VIDEOS_STORE', 'videos')

        # ä¸´æ—¶æ–‡ä»¶ç›®å½•
        self.temp_store = os.path.join(os.path.dirname(self.videos_store), 'temp_downloads')

        # FFmpegå¤šçº¿ç¨‹ä¸‹è½½é…ç½®
        self.max_threads = self.settings.get('FFMPEG_MAX_THREADS', 20)
        # å¹¶è¡Œä¸‹è½½é…ç½®
        self.max_concurrent_downloads = self.settings.get('MAX_CONCURRENT_DOWNLOADS', 5)

        # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
        for directory in [self.videos_store, self.temp_store]:
            if not os.path.exists(directory):
                os.makedirs(directory)
                self.log(f"åˆ›å»ºç›®å½•: {directory}")

        # åˆ›å»ºçº¿ç¨‹æ± ç”¨äºå¹¶è¡Œä¸‹è½½
        self.download_executor = concurrent.futures.ThreadPoolExecutor(
            max_workers=self.max_concurrent_downloads,
            thread_name_prefix="M3U8Download"
        )

        # æ­£åœ¨ä¸‹è½½çš„è§†é¢‘URLé›†åˆ
        self.downloading_urls = set()
        # å·²å¤„ç†çš„è§†é¢‘URLé›†åˆï¼ˆç”¨äºURLçº§åˆ«å»é‡ï¼‰
        self.processed_urls = set()
        # æ´»åŠ¨ä¸‹è½½ä»»åŠ¡è®¡æ•°å™¨
        self.active_downloads = 0
        # çº¿ç¨‹é”
        self.lock = threading.RLock()

        # ä¸‹è½½è¿›åº¦ç»Ÿè®¡
        self.download_stats = {
            'total_received': 0,        # æ€»æ¥æ”¶æ•°é‡ï¼ˆæ¥æ”¶åˆ°çš„itemæ•°é‡ï¼‰
            'download_success': 0,      # ä¸‹è½½æˆåŠŸæ•°é‡
            'download_failed': 0,       # ä¸‹è½½å¤±è´¥æ•°é‡
            'skipped_duplicate': 0,     # è·³è¿‡çš„é‡å¤é¡¹
            'queued_downloads': 0,      # æ’é˜Ÿä¸­çš„ä¸‹è½½ä»»åŠ¡
            'start_time': time.time(),  # å¼€å§‹æ—¶é—´
        }
        
        # å½“å‰æ­£åœ¨ä¸‹è½½çš„è§†é¢‘ä¿¡æ¯ {url: {'title': title, 'start_time': time}}
        self.current_downloads = {}

        # åˆå§‹åŒ–æ’é™¤æ ‡é¢˜åˆ—è¡¨
        self.excluded_titles = self._load_excluded_titles()
        # åˆå§‹åŒ–å·²ä¸‹è½½URLåˆ—è¡¨
        self.excluded_urls = self._load_excluded_urls()

        self.log(f"M3U8Pipelineåˆå§‹åŒ–å®Œæˆ - æœ€å¤§å¹¶è¡Œä¸‹è½½æ•°: {self.max_concurrent_downloads}, FFmpegçº¿ç¨‹æ•°: {self.max_threads}")
        self.log(f"è§†é¢‘å­˜å‚¨ç›®å½•: {self.videos_store}")
        self.log(f"ä¸´æ—¶æ–‡ä»¶ç›®å½•: {self.temp_store}")
        self.log(f"å·²åŠ è½½æ’é™¤æ ‡é¢˜æ•°é‡: {len(self.excluded_titles)}")
        self.log(f"å·²åŠ è½½æ’é™¤URLæ•°é‡: {len(self.excluded_urls)}")

        # å¯åŠ¨è¿›åº¦ç›‘æ§çº¿ç¨‹
        self.progress_monitor_thread = threading.Thread(target=self._progress_monitor, daemon=True)
        self.progress_monitor_thread.start()
        self.log("ğŸ“Š ä¸‹è½½è¿›åº¦ç›‘æ§å·²å¯åŠ¨")

    def process_item(self, item, spider):
        """
        å¤„ç†æ¯ä¸ªåŒ…å«m3u8_urlçš„itemï¼Œæ”¯æŒURLå’Œæ ‡é¢˜åŒé‡å»é‡
        """
        # æ£€æŸ¥itemæ˜¯å¦åŒ…å«m3u8_urlå­—æ®µ
        if 'm3u8_url' not in item:
            self.log(f"Item {item.get('title', 'Unknown')} æ²¡æœ‰m3u8_urlå­—æ®µï¼Œè·³è¿‡")
            return item

        m3u8_url = item['m3u8_url']
        title = item.get('title', 'Unknown')

        with self.lock:
            self.download_stats['total_received'] += 1

        self.log(f"ğŸ¯ M3U8Pipelineæ¥æ”¶åˆ°item [{self.download_stats['total_received']}]: {title}")

        # ç¬¬ä¸€é‡å»é‡ï¼šæ£€æŸ¥URLæ˜¯å¦å·²ç»å¤„ç†è¿‡
        if m3u8_url in self.processed_urls:
            self.log(f"ğŸ”„ URL '{m3u8_url}' å·²å¤„ç†è¿‡ï¼Œè·³è¿‡é‡å¤ä¸‹è½½")
            with self.lock:
                self.download_stats['skipped_duplicate'] += 1
            return item

        # ç¬¬äºŒé‡å»é‡ï¼šæ£€æŸ¥URLæ˜¯å¦åœ¨å·²ä¸‹è½½URLåˆ—è¡¨ä¸­
        if self._is_url_excluded(m3u8_url):
            self.log(f"âŒ URL '{m3u8_url}' å·²ä¸‹è½½è¿‡ï¼Œè·³è¿‡ä¸‹è½½")
            # æ·»åŠ åˆ°å·²å¤„ç†é›†åˆ
            self.processed_urls.add(m3u8_url)
            with self.lock:
                self.download_stats['skipped_duplicate'] += 1
            return item

        # ç¬¬ä¸‰é‡å»é‡ï¼šæ£€æŸ¥æ ‡é¢˜æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­ï¼ˆå·²ä¸‹è½½è¿‡ï¼‰
        if self._is_title_excluded(title):
            self.log(f"âŒ è§†é¢‘ '{title}' å·²ä¸‹è½½è¿‡ï¼Œè·³è¿‡ä¸‹è½½")
            # æ·»åŠ åˆ°å·²å¤„ç†é›†åˆ
            self.processed_urls.add(m3u8_url)
            with self.lock:
                self.download_stats['skipped_duplicate'] += 1
            return item

        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨ä¸‹è½½
        with self.lock:
            if m3u8_url in self.downloading_urls:
                self.log(f"â³ è§†é¢‘ '{title}' æ­£åœ¨ä¸‹è½½ä¸­ï¼Œè·³è¿‡é‡å¤ä¸‹è½½")
                self.download_stats['skipped_duplicate'] += 1
                return item
            
            # æ·»åŠ åˆ°ä¸‹è½½é›†åˆå’Œå·²å¤„ç†é›†åˆ
            self.downloading_urls.add(m3u8_url)
            self.processed_urls.add(m3u8_url)
            
            # è®°å½•å½“å‰ä¸‹è½½ä¿¡æ¯
            self.current_downloads[m3u8_url] = {
                'title': title,
                'start_time': time.time()
            }

            # æ›´æ–°æ’é˜Ÿä¸­çš„ä¸‹è½½ä»»åŠ¡æ•°é‡
            self.download_stats['queued_downloads'] += 1

        # æäº¤ä¸‹è½½ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
        self.log(f"ğŸš€ æäº¤ä¸‹è½½ä»»åŠ¡ [æ’é˜Ÿ: {self.download_stats['queued_downloads']}, æ´»åŠ¨: {len(self.current_downloads)}/{self.max_concurrent_downloads}]: {title}")
        future = self.download_executor.submit(self._download_video, item)
        future.add_done_callback(lambda f: self._download_completed(f, m3u8_url, title))

        return item

    def _download_video(self, item):
        """
        ä¸‹è½½è§†é¢‘çš„ä¸»è¦æ–¹æ³•
        """
        title = item.get('title', 'Unknown')
        m3u8_url = item['m3u8_url']

        try:
            with self.lock:
                self.active_downloads += 1
                self.download_stats['queued_downloads'] -= 1

            self.log(f"ğŸš€ å¼€å§‹ä¸‹è½½è§†é¢‘: {title}")

            # è·å–è¾“å‡ºç›®å½•å’Œæ–‡ä»¶è·¯å¾„
            dir_path = self.get_directory_path(item)
            if not os.path.exists(dir_path):
                os.makedirs(dir_path)

            # ç”Ÿæˆä¸´æ—¶æ–‡ä»¶å’Œæœ€ç»ˆæ–‡ä»¶è·¯å¾„
            temp_file = self._get_temp_file_path(title)
            final_file = self._get_final_file_path(item, title)

            # ä½¿ç”¨ffmpegä¸‹è½½
            success = self._download_m3u8_with_ffmpeg(m3u8_url, temp_file, title)

            if success and os.path.exists(temp_file):
                # ç§»åŠ¨ä¸´æ—¶æ–‡ä»¶åˆ°æœ€ç»ˆä½ç½®
                shutil.move(temp_file, final_file)
                
                # è®°å½•æ ‡é¢˜åˆ°å·²ä¸‹è½½åˆ—è¡¨
                self._append_to_excluded_list(title)
                # è®°å½•URLåˆ°å·²ä¸‹è½½åˆ—è¡¨
                self._append_to_excluded_urls(m3u8_url)
                
                self.log(f"âœ… è§†é¢‘ä¸‹è½½å®Œæˆ: {title}")
                return {'success': True, 'title': title, 'file_path': final_file}
            else:
                self.log(f"âŒ è§†é¢‘ä¸‹è½½å¤±è´¥: {title}")
                return {'success': False, 'title': title}

        except Exception as e:
            self.log(f"âŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {title}, é”™è¯¯: {e}")
            return {'success': False, 'title': title, 'error': str(e)}
        finally:
            with self.lock:
                self.active_downloads -= 1

    def _download_m3u8_with_ffmpeg(self, url, temp_file_path, title):
        """
        ä½¿ç”¨ffmpegä¸‹è½½m3u8æ–‡ä»¶
        """
        try:
            # æ„å»ºffmpegå‘½ä»¤
            cmd = [
                'ffmpeg',
                '-allowed_extensions', 'ALL',  # å…è®¸æ‰€æœ‰æ‰©å±•
                '-threads', str(self.max_threads),  # è®¾ç½®çº¿ç¨‹æ•°
                '-user_agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',  # è®¾ç½®User-Agent
                '-i', url,  # è¾“å…¥URL
                '-c', 'copy',  # å¤åˆ¶æµï¼Œä¸é‡æ–°ç¼–ç 
                '-bsf:a', 'aac_adtstoasc',  # éŸ³é¢‘æµå¤„ç†
                '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                temp_file_path
            ]

            self.log(f"ğŸš€ å¼€å§‹ffmpegä¸‹è½½ (çº¿ç¨‹æ•°: {self.max_threads}): {title}")

            # æ‰§è¡Œå‘½ä»¤
            result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                                    universal_newlines=True, timeout=3600)  # 1å°æ—¶è¶…æ—¶

            if result.returncode == 0:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„ä¸‹è½½å®Œæˆ
                if os.path.exists(temp_file_path) and os.path.getsize(temp_file_path) > 0:
                    self.log(f"âœ… ffmpegä¸‹è½½å®Œæˆ: {title}")
                    return True
                else:
                    self.log(f"âŒ ä¸‹è½½å®Œæˆä½†æ–‡ä»¶æ— æ•ˆ: {title}")
                    return False
            else:
                self.log(f"âŒ ffmpegä¸‹è½½å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}, è§†é¢‘: {title}")
                self.log(f"é”™è¯¯è¾“å‡º: {result.stderr}")
                return False

        except subprocess.TimeoutExpired:
            self.log(f"â° ffmpegä¸‹è½½è¶…æ—¶: {title}")
            return False
        except Exception as e:
            self.log(f"âŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {title}, é”™è¯¯: {e}")
            return False

    def _download_completed(self, future, m3u8_url, title):
        """
        ä¸‹è½½å®Œæˆçš„å›è°ƒå‡½æ•°
        """
        try:
            result = future.result()
            
            # è®¡ç®—ä¸‹è½½è€—æ—¶
            download_time = 0
            if m3u8_url in self.current_downloads:
                download_time = time.time() - self.current_downloads[m3u8_url]['start_time']
            
            with self.lock:
                # å‡å°‘æ’é˜Ÿä¸­çš„ä»»åŠ¡æ•°é‡
                self.download_stats['queued_downloads'] -= 1
                
                if result['success']:
                    self.download_stats['download_success'] += 1
                    self.log(f"âœ… M3U8è§†é¢‘ä¸‹è½½æˆåŠŸ: {title} (è€—æ—¶: {download_time:.1f}ç§’)")
                    # è®°å½•URLåˆ°å·²ä¸‹è½½URLåˆ—è¡¨
                    self._append_to_excluded_urls(m3u8_url)
                else:
                    self.download_stats['download_failed'] += 1
                    self.log(f"âŒ M3U8è§†é¢‘ä¸‹è½½å¤±è´¥: {title} (è€—æ—¶: {download_time:.1f}ç§’)")
        except Exception as e:
            with self.lock:
                self.download_stats['queued_downloads'] -= 1
                self.download_stats['download_failed'] += 1
            self.log(f"ä¸‹è½½å›è°ƒå¤„ç†å¤±è´¥: {title}, é”™è¯¯: {e}")
        finally:
            # ä»ä¸‹è½½é›†åˆä¸­ç§»é™¤
            with self.lock:
                self.downloading_urls.discard(m3u8_url)
                self.current_downloads.pop(m3u8_url, None)

    def _load_excluded_titles(self):
        """
        åŠ è½½ä» utils/51chigua.txt æ–‡ä»¶ä¸­æ’é™¤çš„æ ‡é¢˜åˆ—è¡¨
        """
        excluded_titles = set()
        chigua_path = os.path.join(os.path.dirname(__file__), 'utils', '51chigua.txt')

        if os.path.exists(chigua_path):
            try:
                with open(chigua_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):  # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
                            excluded_titles.add(line)
                self.log(f"æˆåŠŸä» {chigua_path} åŠ è½½ {len(excluded_titles)} ä¸ªæ’é™¤æ ‡é¢˜")
            except Exception as e:
                self.log(f"åŠ è½½æ’é™¤æ ‡é¢˜æ–‡ä»¶å¤±è´¥: {e}")
        else:
            self.log(f"æ’é™¤æ ‡é¢˜æ–‡ä»¶ä¸å­˜åœ¨: {chigua_path}")

        return excluded_titles

    def _load_excluded_urls(self):
        """
        åŠ è½½å·²ä¸‹è½½è¿‡çš„URLåˆ—è¡¨
        """
        excluded_urls = set()
        urls_path = os.path.join(os.path.dirname(__file__), 'utils', 'm3u8_urls.txt')

        if os.path.exists(urls_path):
            try:
                with open(urls_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):  # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
                            excluded_urls.add(line)
                self.log(f"æˆåŠŸä» {urls_path} åŠ è½½ {len(excluded_urls)} ä¸ªæ’é™¤URL")
            except Exception as e:
                self.log(f"åŠ è½½æ’é™¤URLæ–‡ä»¶å¤±è´¥: {e}")
        else:
            self.log(f"æ’é™¤URLæ–‡ä»¶ä¸å­˜åœ¨: {urls_path}ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(urls_path), exist_ok=True)
            # åˆ›å»ºç©ºæ–‡ä»¶
            with open(urls_path, 'w', encoding='utf-8') as f:
                f.write("# å·²ä¸‹è½½çš„M3U8è§†é¢‘URLåˆ—è¡¨\n")

        return excluded_urls

    def _is_title_excluded(self, title):
        """
        æ£€æŸ¥æ ‡é¢˜æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
        """
        return title in self.excluded_titles

    def _is_url_excluded(self, url):
        """
        æ£€æŸ¥URLæ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
        """
        return url in self.excluded_urls

    def _append_to_excluded_list(self, title):
        """
        å°†æˆåŠŸä¸‹è½½çš„è§†é¢‘æ ‡é¢˜è¿½åŠ åˆ°æ’é™¤åˆ—è¡¨æ–‡ä»¶ä¸­
        """
        try:
            chigua_path = os.path.join(os.path.dirname(__file__), 'utils', '51chigua.txt')

            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(chigua_path), exist_ok=True)

            # è¿½åŠ æ ‡é¢˜åˆ°æ–‡ä»¶
            with open(chigua_path, 'a', encoding='utf-8') as f:
                f.write(f"\n{title}")

            # åŒæ—¶æ·»åŠ åˆ°å†…å­˜ä¸­çš„æ’é™¤é›†åˆ
            self.excluded_titles.add(title)

            self.log(f"âœ… å·²å°†æ ‡é¢˜ '{title}' è¿½åŠ åˆ°æ’é™¤åˆ—è¡¨æ–‡ä»¶")

        except Exception as e:
            self.log(f"âŒ è¿½åŠ æ ‡é¢˜åˆ°æ’é™¤åˆ—è¡¨å¤±è´¥: {title}, é”™è¯¯: {e}")

    def _append_to_excluded_urls(self, url):
        """
        å°†æˆåŠŸä¸‹è½½çš„è§†é¢‘URLè¿½åŠ åˆ°æ’é™¤åˆ—è¡¨æ–‡ä»¶ä¸­
        """
        try:
            urls_path = os.path.join(os.path.dirname(__file__), 'utils', 'm3u8_urls.txt')

            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(urls_path), exist_ok=True)

            # è¿½åŠ URLåˆ°æ–‡ä»¶
            with open(urls_path, 'a', encoding='utf-8') as f:
                f.write(f"{url}\n")

            # åŒæ—¶æ·»åŠ åˆ°å†…å­˜ä¸­çš„æ’é™¤é›†åˆ
            self.excluded_urls.add(url)

            self.log(f"âœ… å·²å°†URLè¿½åŠ åˆ°æ’é™¤åˆ—è¡¨æ–‡ä»¶")

        except Exception as e:
            self.log(f"âŒ è¿½åŠ URLåˆ°æ’é™¤åˆ—è¡¨å¤±è´¥: {url}, é”™è¯¯: {e}")

    def _get_temp_file_path(self, title):
        """
        è·å–ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        """
        cleaned_title = self._clean_filename(title)
        temp_filename = f"{cleaned_title}_{int(time.time())}.tmp.mp4"
        return os.path.join(self.temp_store, temp_filename)

    def _get_final_file_path(self, item, title):
        """
        è·å–æœ€ç»ˆæ–‡ä»¶è·¯å¾„
        """
        dir_path = self.get_directory_path(item)
        cleaned_title = self._clean_filename(title)
        final_filename = f"{cleaned_title}.mp4"
        return os.path.join(dir_path, final_filename)

    def _clean_filename(self, filename):
        """
        æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤æˆ–æ›¿æ¢ä¸åˆæ³•å­—ç¬¦
        """
        # å®šä¹‰ä¸åˆæ³•å­—ç¬¦
        illegal_chars = ['<', '>', ':', '"', '/', '\\', '|', '?', '*']

        cleaned = filename
        for char in illegal_chars:
            cleaned = cleaned.replace(char, '_')

        # ç§»é™¤é¦–å°¾ç©ºæ ¼å’Œç‚¹
        cleaned = cleaned.strip(' .')

        # é™åˆ¶æ–‡ä»¶åé•¿åº¦
        if len(cleaned) > 100:
            cleaned = cleaned[:100]

        return cleaned

    def get_directory_path(self, item):
        """
        è¿”å›è§†é¢‘æ–‡ä»¶çš„å­˜å‚¨ç›®å½•è·¯å¾„
        """
        dir_path = os.path.join(self.videos_store, item.get('site', 'default'))
        return dir_path

    def close_spider(self, spider):
        """
        çˆ¬è™«å…³é—­æ—¶ç­‰å¾…æ‰€æœ‰ä¸‹è½½ä»»åŠ¡å®Œæˆ
        """
        self.log("ğŸ”„ çˆ¬è™«å³å°†å…³é—­ï¼Œç­‰å¾…æ‰€æœ‰M3U8ä¸‹è½½ä»»åŠ¡å®Œæˆ...")

        # æ˜¾ç¤ºå…³é—­æ—¶çš„è¿›åº¦æŠ¥å‘Š
        self._show_progress_report()

        with self.lock:
            if self.active_downloads == 0:
                self.log("âœ… æ²¡æœ‰æ´»åŠ¨çš„ä¸‹è½½ä»»åŠ¡ï¼Œç›´æ¥å…³é—­çˆ¬è™«")
                self._show_final_statistics()
                self._cleanup_resources()
                return

            self.log(f"â³ ç­‰å¾… {self.active_downloads} ä¸ªä¸‹è½½ä»»åŠ¡å®Œæˆ...")

        # ç­‰å¾…æ‰€æœ‰ä¸‹è½½å®Œæˆï¼ˆæœ€å¤šç­‰å¾…2å°æ—¶ï¼‰
        start_time = time.time()
        while self.active_downloads > 0 and (time.time() - start_time) < 7200:
            time.sleep(5)
            # æ¯30ç§’æ˜¾ç¤ºä¸€æ¬¡ç­‰å¾…çŠ¶æ€
            if int(time.time() - start_time) % 30 == 0:
                self.log(f"â³ ä»åœ¨ç­‰å¾… {self.active_downloads} ä¸ªä¸‹è½½ä»»åŠ¡å®Œæˆ... (å·²ç­‰å¾… {int(time.time() - start_time)}ç§’)")

        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        self._show_final_statistics()
        self._cleanup_resources()
        self.log("ğŸ‰ æ‰€æœ‰M3U8ä¸‹è½½ä»»åŠ¡å·²å®Œæˆï¼Œçˆ¬è™«å¯ä»¥å®‰å…¨å…³é—­")

    def _show_final_statistics(self):
        """
        æ˜¾ç¤ºæœ€ç»ˆçš„ä¸‹è½½ç»Ÿè®¡æŠ¥å‘Š
        """
        stats = self._get_download_statistics()
        runtime = time.time() - stats['start_time']
        hours, remainder = divmod(runtime, 3600)
        minutes, seconds = divmod(remainder, 60)
        runtime_str = f"{int(hours)}h{int(minutes)}m{int(seconds)}s"
        
        total_attempts = stats['download_success'] + stats['download_failed']
        success_rate = (stats['download_success'] / total_attempts * 100) if total_attempts > 0 else 0
        
        # è®¡ç®—å¹³å‡ä¸‹è½½é€Ÿåº¦
        avg_speed = stats['download_success'] / (runtime / 60) if runtime > 0 else 0  # æ¯åˆ†é’ŸæˆåŠŸä¸‹è½½æ•°
        
        self.log("ğŸŠ" * 40)
        self.log("ğŸ M3U8ä¸‹è½½ç®¡é“æœ€ç»ˆç»Ÿè®¡æŠ¥å‘Š")
        self.log("ğŸŠ" * 40)
        self.log(f"â±ï¸  æ€»è¿è¡Œæ—¶é—´: {runtime_str}")
        self.log(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
        self.log(f"   ğŸ“‹ æ€»æ¥æ”¶æ•°é‡: {stats['total_received']}")
        self.log(f"   âœ… ä¸‹è½½æˆåŠŸ: {stats['download_success']}")
        self.log(f"   âŒ ä¸‹è½½å¤±è´¥: {stats['download_failed']}")
        self.log(f"   ğŸ”„ è·³è¿‡é‡å¤: {stats['skipped_duplicate']}")
        self.log(f"   â³ å‰©ä½™æ’é˜Ÿ: {stats['queued_downloads']}")
        self.log(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")
        self.log(f"âš¡ å¹³å‡é€Ÿåº¦: {avg_speed:.1f} è§†é¢‘/åˆ†é’Ÿ")
        self.log(f"ğŸ“ å­˜å‚¨ä½ç½®: {self.videos_store}")
        self.log("ğŸŠ" * 40)

    def _cleanup_resources(self):
        """
        æ¸…ç†èµ„æº
        """
        try:
            # å…³é—­çº¿ç¨‹æ± 
            if hasattr(self, 'download_executor'):
                self.download_executor.shutdown(wait=False)
                self.log("ğŸ§¹ ä¸‹è½½çº¿ç¨‹æ± å·²å…³é—­")

        except Exception as e:
            self.log(f"âŒ å…³é—­èµ„æºæ—¶å‡ºé”™: {e}")

    def _progress_monitor(self):
        """
        è¿›åº¦ç›‘æ§çº¿ç¨‹ï¼Œå®šæ—¶æ˜¾ç¤ºä¸‹è½½çŠ¶æ€
        """
        last_report_time = time.time()
        report_interval = 30  # æ¯30ç§’æŠ¥å‘Šä¸€æ¬¡è¿›åº¦
        
        while True:
            try:
                time.sleep(5)  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
                current_time = time.time()
                
                # æ¯30ç§’æˆ–æœ‰æ´»åŠ¨ä¸‹è½½æ—¶æ˜¾ç¤ºè¯¦ç»†è¿›åº¦
                if (current_time - last_report_time) >= report_interval or self.active_downloads > 0:
                    self._show_progress_report()
                    last_report_time = current_time
                    
                # å¦‚æœæ²¡æœ‰æ´»åŠ¨ä¸‹è½½ï¼Œå»¶é•¿æ£€æŸ¥é—´éš”
                if self.active_downloads == 0:
                    time.sleep(25)  # æ€»å…±30ç§’é—´éš”
                    
            except Exception as e:
                self.log(f"è¿›åº¦ç›‘æ§å¼‚å¸¸: {e}")

    def _show_progress_report(self):
        """
        æ˜¾ç¤ºè¯¦ç»†çš„è¿›åº¦æŠ¥å‘Š
        """
        # ä½¿ç”¨_get_download_statisticså‡½æ•°è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = self._get_download_statistics()
        
        with self.lock:
            current_downloads_info = self.current_downloads.copy()
        
        # è®¡ç®—è¿è¡Œæ—¶é—´
        runtime = time.time() - stats['start_time']
        hours, remainder = divmod(runtime, 3600)
        minutes, seconds = divmod(remainder, 60)
        runtime_str = f"{int(hours)}h{int(minutes)}m{int(seconds)}s"
        
        # è®¡ç®—æˆåŠŸç‡
        total_attempts = stats['download_success'] + stats['download_failed']
        success_rate = (stats['download_success'] / total_attempts * 100) if total_attempts > 0 else 0
        
        # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
        self.log("=" * 80)
        self.log(f"ğŸ“Š ä¸‹è½½è¿›åº¦æŠ¥å‘Š - è¿è¡Œæ—¶é—´: {runtime_str}")
        self.log(f"ğŸ“‹ æ€»æ¥æ”¶: {stats['total_received']} | âœ… æˆåŠŸ: {stats['download_success']} | âŒ å¤±è´¥: {stats['download_failed']} | ğŸ”„ è·³è¿‡: {stats['skipped_duplicate']} | â³ æ’é˜Ÿ: {stats['queued_downloads']}")
        self.log(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}% | ğŸƒ æ´»åŠ¨ä¸‹è½½: {stats['active_downloads']}/{self.max_concurrent_downloads}")
        
        # æ˜¾ç¤ºå½“å‰æ­£åœ¨ä¸‹è½½çš„è§†é¢‘
        if current_downloads_info:
            self.log("ğŸ¬ å½“å‰ä¸‹è½½ä¸­:")
            for i, (url, info) in enumerate(current_downloads_info.items(), 1):
                download_time = time.time() - info['start_time']
                self.log(f"   {i}. {info['title']} (å·²è¿›è¡Œ {download_time:.0f}ç§’)")
        else:
            self.log("ğŸ˜´ å½“å‰æ— ä¸‹è½½ä»»åŠ¡")
        
        self.log("=" * 80)

    def _get_download_statistics(self):
        """
        è·å–ä¸‹è½½ç»Ÿè®¡ä¿¡æ¯
        """
        with self.lock:
            stats = self.download_stats.copy()
            stats['active_downloads'] = self.active_downloads
            stats['current_downloads'] = len(self.current_downloads)
            
        return stats
