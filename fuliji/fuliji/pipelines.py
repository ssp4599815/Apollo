# !/usr/bin/env python
# -*-coding:utf-8 -*-
import concurrent.futures
import logging
import os
import shutil
import subprocess
import threading
import time

import scrapy
from scrapy.exceptions import DropItem
from scrapy.pipelines.images import ImagesPipeline
from scrapy.utils.project import get_project_settings

from .database import DownloadDatabase


class ImgPipeline(ImagesPipeline):

    def get_media_requests(self, item, info):
        # è·å–å°†ç”¨äºå­˜å‚¨å›¾ç‰‡çš„ç›®å½•è·¯å¾„
        dir_path = self.get_directory_path(item)
        logging.info("Checking if directory exists at: %s" % dir_path)
        if not os.path.exists(dir_path):
            logging.info("Directory does not exist, downloading images")
            for index, image_url in enumerate(item['image_urls']):
                yield scrapy.Request(image_url, meta={'item': item, 'index': index})
        else:
            logging.info("Directory already exists, skipping download for images in: %s" % dir_path)

    def item_completed(self, results, item, info):
        image_paths = [x['path'] for ok, x in results if ok]
        # logging.info("image_paths: %s" % image_paths)
        if not image_paths:
            raise DropItem("No images downloaded %s" % image_paths)
        item['image_paths'] = image_paths
        # æ‰“å°å®Œç»“çš„æ—¥å¿—
        logging.info("Download images completed: %s" % item['title'])

        return item

    def file_path(self, request, response=None, info=None):
        item = request.meta['item']
        index = request.meta['index']
        url = request.url
        # è·å–å›¾ç‰‡æ ¼å¼
        image_format = url.split('.')[-1]
        file_name = f"{item['title']}-{index + 1}"  # ä»¥å›¾ç‰‡URLçš„é¡ºåºå‘½åæ–‡ä»¶
        # logging.info("file_name: %s" % file_name)
        return f"{item['title']}/{file_name}.{image_format}"

    def get_directory_path(self, item):
        """
        Returns the directory path for the given item.
        """
        settings = get_project_settings()
        images_store = settings.get('IMAGES_STORE', '')
        dir_path = os.path.join(images_store, item['site'], item['title'])
        return dir_path


class M3U8Pipeline:
    """
    æ”¹è¿›çš„M3U8è§†é¢‘ä¸‹è½½ç®¡é“ï¼Œæ”¯æŒï¼š
    1. æ–­ç‚¹ç»­ä¼ 
    2. ä¸´æ—¶æ–‡ä»¶ç®¡ç†  
    3. SQLiteæ•°æ®åº“è®°å½•
    4. è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    """

    def __init__(self):
        self.settings = get_project_settings()
        self.videos_store = self.settings.get('VIDEOS_STORE', 'videos')

        # ä¸´æ—¶æ–‡ä»¶ç›®å½•
        self.temp_store = os.path.join(os.path.dirname(self.videos_store), 'temp_downloads')

        # æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        self.db_path = os.path.join(os.path.dirname(self.videos_store), 'downloads.db')

        # FFmpegå¤šçº¿ç¨‹ä¸‹è½½é…ç½®
        self.max_threads = self.settings.get('FFMPEG_MAX_THREADS', 20)
        # å¹¶è¡Œä¸‹è½½é…ç½®
        self.max_concurrent_downloads = self.settings.get('MAX_CONCURRENT_DOWNLOADS', 5)

        # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
        for directory in [self.videos_store, self.temp_store]:
            if not os.path.exists(directory):
                os.makedirs(directory)
                logging.info(f"åˆ›å»ºç›®å½•: {directory}")

        # åˆå§‹åŒ–æ•°æ®åº“
        self.db = DownloadDatabase(self.db_path)

        # åˆ›å»ºçº¿ç¨‹æ± ç”¨äºå¹¶è¡Œä¸‹è½½
        self.download_executor = concurrent.futures.ThreadPoolExecutor(
            max_workers=self.max_concurrent_downloads,
            thread_name_prefix="M3U8Download"
        )

        # æ­£åœ¨ä¸‹è½½çš„è§†é¢‘URLé›†åˆ
        self.downloading_urls = set()
        # æ´»åŠ¨ä¸‹è½½ä»»åŠ¡è®¡æ•°å™¨
        self.active_downloads = 0
        # æ´»åŠ¨ä¸‹è½½ä»»åŠ¡æ¡ä»¶å˜é‡ï¼ˆç”¨äºç­‰å¾…æ‰€æœ‰ä¸‹è½½å®Œæˆï¼‰
        self.downloads_done = threading.Condition()
        # çº¿ç¨‹é”
        self.lock = threading.RLock()
        # æ˜¯å¦å·²é€šçŸ¥çˆ¬è™«ç»“æŸ
        self.shutdown_notified = False

        logging.info(
            f"M3U8Pipelineåˆå§‹åŒ–å®Œæˆ - æœ€å¤§å¹¶è¡Œä¸‹è½½æ•°: {self.max_concurrent_downloads}, FFmpegçº¿ç¨‹æ•°: {self.max_threads}")
        logging.info(f"è§†é¢‘å­˜å‚¨ç›®å½•: {self.videos_store}")
        logging.info(f"ä¸´æ—¶æ–‡ä»¶ç›®å½•: {self.temp_store}")
        logging.info(f"æ•°æ®åº“æ–‡ä»¶: {self.db_path}")

        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        self.monitor_thread = threading.Thread(target=self._monitor_downloads, daemon=True)
        self.monitor_thread.start()

    def _get_url_hash(self, url):
        """ç”ŸæˆURLçš„å”¯ä¸€å“ˆå¸Œæ ‡è¯†"""
        return self.db.get_url_hash(url)

    def _is_download_completed(self, url, title):
        """æ£€æŸ¥è§†é¢‘æ˜¯å¦å·²ç»ä¸‹è½½å®Œæˆ"""
        completed, file_path = self.db.is_download_completed(url)

        if completed:
            logging.info(f"è§†é¢‘ {title} å·²ä¸‹è½½å®Œæˆï¼Œæ–‡ä»¶è·¯å¾„: {file_path}")
            return True

        return False

    def _get_temp_file_path(self, url, title):
        """è·å–ä¸´æ—¶æ–‡ä»¶è·¯å¾„"""
        # å…ˆå°è¯•ä»æ•°æ®åº“è·å–ç°æœ‰çš„ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        existing_temp_path = self.db.get_temp_file_path(url)
        if existing_temp_path and os.path.exists(existing_temp_path):
            return existing_temp_path

        # ç”Ÿæˆæ–°çš„ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        url_hash = self._get_url_hash(url)
        cleaned_title = self.clean_filename(title)
        temp_filename = f"{cleaned_title}_{url_hash}.tmp.mp4"
        return os.path.join(self.temp_store, temp_filename)

    def _get_final_file_path(self, item, title):
        """è·å–æœ€ç»ˆæ–‡ä»¶è·¯å¾„"""
        dir_path = self.get_directory_path(item)
        final_filename = self.generate_unique_filename(dir_path, title, '.mp4')
        return os.path.join(dir_path, final_filename)

    def process_item(self, item, spider):
        """
        å¤„ç†æ¯ä¸ªåŒ…å«m3u8_urlçš„item
        æ£€æŸ¥æ˜¯å¦å·²ä¸‹è½½å®Œæˆï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
        """
        # æ£€æŸ¥itemæ˜¯å¦åŒ…å«m3u8_urlå­—æ®µ
        if 'm3u8_url' not in item:
            logging.info(f"Item {item.get('title', 'Unknown')} æ²¡æœ‰m3u8_urlå­—æ®µï¼Œè·³è¿‡")
            return item

        m3u8_url = item['m3u8_url']
        title = item.get('title', 'Unknown')
        site = item.get('site', 'unknown')

        logging.info(f"M3U8Pipelineæ¥æ”¶åˆ°item: {title}")

        # æ£€æŸ¥æ˜¯å¦å·²ç»ä¸‹è½½å®Œæˆ
        if self._is_download_completed(m3u8_url, title):
            logging.info(f"è§†é¢‘ {title} å·²ä¸‹è½½å®Œæˆï¼Œè·³è¿‡ä¸‹è½½")
            return item

        # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨ä¸‹è½½é˜Ÿåˆ—ä¸­
        with self.lock:
            if m3u8_url in self.downloading_urls:
                logging.info(f"è§†é¢‘ {title} å·²åœ¨ä¸‹è½½é˜Ÿåˆ—ä¸­ï¼Œè·³è¿‡")
                return item

            # æ ‡è®°ä¸ºæ­£åœ¨ä¸‹è½½
            self.downloading_urls.add(m3u8_url)
            # å¢åŠ æ´»åŠ¨ä¸‹è½½è®¡æ•°
            self.active_downloads += 1

        # è·å–å­˜å‚¨è·¯å¾„
        dir_path = self.get_directory_path(item)

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if not os.path.exists(dir_path):
            os.makedirs(dir_path)
            logging.info(f"åˆ›å»ºç›®å½•: {dir_path}")

        # è·å–ä¸´æ—¶æ–‡ä»¶è·¯å¾„å¹¶æ·»åŠ æ•°æ®åº“è®°å½•
        temp_file_path = self._get_temp_file_path(m3u8_url, title)
        self.db.add_download_record(m3u8_url, title, site, temp_file_path)

        # æäº¤åˆ°çº¿ç¨‹æ± å¼‚æ­¥ä¸‹è½½
        future = self.download_executor.submit(self._download_video_async, item, dir_path)

        # æ·»åŠ å®Œæˆå›è°ƒ
        future.add_done_callback(lambda f: self._download_completed(f, m3u8_url, title))

        logging.info(f"å·²æäº¤M3U8ä¸‹è½½ä»»åŠ¡åˆ°çº¿ç¨‹æ± : {title}")

        return item

    def _monitor_downloads(self):
        """
        ç›‘æ§çº¿ç¨‹ï¼Œæ£€æŸ¥å¹¶æ˜¾ç¤ºä¸‹è½½è¿›åº¦
        """
        last_count = -1
        while True:
            time.sleep(5)  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
            with self.lock:
                if self.active_downloads != last_count:
                    last_count = self.active_downloads
                    if self.active_downloads > 0:
                        logging.info(f"å½“å‰æ­£åœ¨è¿›è¡Œçš„ä¸‹è½½ä»»åŠ¡: {self.active_downloads}")

                # å¦‚æœæ²¡æœ‰æ´»åŠ¨ä¸‹è½½ä¸”å·²ç»é€šçŸ¥è¿‡å…³é—­ï¼Œåˆ™é€€å‡ºç›‘æ§
                if self.active_downloads == 0 and self.shutdown_notified:
                    break

    def _download_video_async(self, item, dir_path):
        """
        å¼‚æ­¥ä¸‹è½½è§†é¢‘çš„å‡½æ•°ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
        """
        title = item.get('title', 'Unknown')
        m3u8_url = item['m3u8_url']

        try:
            logging.info(f"å¼€å§‹ä¸‹è½½è§†é¢‘: {title}")

            # è·å–ä¸´æ—¶æ–‡ä»¶è·¯å¾„å’Œæœ€ç»ˆæ–‡ä»¶è·¯å¾„
            temp_file_path = self._get_temp_file_path(m3u8_url, title)
            final_file_path = self._get_final_file_path(item, title)

            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¸´æ—¶æ–‡ä»¶ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
            resume_download = os.path.exists(temp_file_path) and os.path.getsize(temp_file_path) > 0

            if resume_download:
                logging.info(f"å‘ç°ä¸´æ—¶æ–‡ä»¶ï¼Œå°è¯•æ–­ç‚¹ç»­ä¼ : {title}")

            # ä¸‹è½½è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            success = self.download_m3u8_with_resume(m3u8_url, temp_file_path, title, resume_download)

            if success:
                # è·å–æ–‡ä»¶å¤§å°
                file_size = os.path.getsize(temp_file_path)

                # ä¸‹è½½æˆåŠŸï¼Œç§»åŠ¨åˆ°æ­£å¼ç›®å½•
                shutil.move(temp_file_path, final_file_path)
                logging.info(f"âœ… è§†é¢‘ä¸‹è½½å®Œæˆï¼Œå·²ç§»åŠ¨åˆ°: {final_file_path}")

                # æ›´æ–°æ•°æ®åº“è®°å½•
                self.db.update_download_status(m3u8_url, 'completed', final_file_path, file_size)

                return {'success': True, 'title': title, 'file_path': final_file_path}
            else:
                # ä¸‹è½½å¤±è´¥ï¼Œæ›´æ–°çŠ¶æ€
                self.db.update_download_status(m3u8_url, 'failed')
                logging.error(f"âŒ è§†é¢‘ä¸‹è½½å¤±è´¥ï¼Œä¸´æ—¶æ–‡ä»¶ä¿ç•™: {temp_file_path}")
                return {'success': False, 'title': title}

        except Exception as e:
            # ä¸‹è½½å¼‚å¸¸ï¼Œæ›´æ–°çŠ¶æ€
            self.db.update_download_status(m3u8_url, 'error')
            logging.error(f"å¼‚æ­¥ä¸‹è½½è§†é¢‘å¤±è´¥: {title}, é”™è¯¯: {e}")
            return {'success': False, 'title': title, 'error': str(e)}

    def _download_completed(self, future, m3u8_url, title):
        """
        ä¸‹è½½å®Œæˆçš„å›è°ƒå‡½æ•°
        """
        try:
            result = future.result()
            if result['success']:
                logging.info(f"âœ… M3U8è§†é¢‘ä¸‹è½½æˆåŠŸ: {title}")
            else:
                logging.error(f"âŒ M3U8è§†é¢‘ä¸‹è½½å¤±è´¥: {title}, é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        except Exception as e:
            logging.error(f"ä¸‹è½½å›è°ƒå¤„ç†å¤±è´¥: {title}, é”™è¯¯: {e}")
        finally:
            # ä»ä¸‹è½½é›†åˆä¸­ç§»é™¤å¹¶å‡å°‘æ´»åŠ¨ä¸‹è½½è®¡æ•°
            with self.lock:
                self.downloading_urls.discard(m3u8_url)
                self.active_downloads -= 1
                logging.info(f"è§†é¢‘ {title} å¤„ç†å®Œæˆï¼Œå‰©ä½™ä¸‹è½½ä»»åŠ¡: {self.active_downloads}")

                # å¦‚æœæ‰€æœ‰ä¸‹è½½éƒ½å®Œæˆäº†ï¼Œé€šçŸ¥æ¡ä»¶å˜é‡
                if self.active_downloads == 0:
                    with self.downloads_done:
                        self.downloads_done.notify_all()

    def download_m3u8_with_resume(self, url, temp_file_path, title, resume=False):
        """
        ä¸‹è½½m3u8æ–‡ä»¶ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
        """
        try:
            # æ„å»ºffmpegå‘½ä»¤
            cmd = [
                'ffmpeg',
                '-allowed_extensions', 'ALL',  # å…è®¸æ‰€æœ‰æ‰©å±•
                '-threads', str(self.max_threads),  # è®¾ç½®çº¿ç¨‹æ•°
                '-http_seekable', '1',  # å¯ç”¨HTTPå¯å¯»å€
                '-user_agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',  # è®¾ç½®User-Agent
                '-i', url,  # è¾“å…¥URL
                '-c', 'copy',  # å¤åˆ¶æµï¼Œä¸é‡æ–°ç¼–ç 
                '-bsf:a', 'aac_adtstoasc',  # éŸ³é¢‘æµå¤„ç†
                '-threads', str(self.max_threads),  # è¾“å‡ºçº¿ç¨‹æ•°
            ]

            # å¦‚æœæ˜¯æ–­ç‚¹ç»­ä¼ ä¸”æ–‡ä»¶å­˜åœ¨ï¼Œåˆ™ä¸è¦†ç›–
            if not resume:
                cmd.append('-y')  # è¦†ç›–è¾“å‡ºæ–‡ä»¶

            cmd.append(temp_file_path)

            if resume:
                logging.info(f"ğŸ”„ æ–­ç‚¹ç»­ä¼ ä¸‹è½½: {title}")
            else:
                logging.info(f"ğŸš€ å¼€å§‹æ–°ä¸‹è½½ (çº¿ç¨‹æ•°: {self.max_threads}): {title}")

            # æ‰§è¡Œå‘½ä»¤å¹¶æ•è·è¾“å‡º
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=3600)  # 1å°æ—¶è¶…æ—¶

            if result.returncode == 0:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„ä¸‹è½½å®Œæˆï¼ˆæ–‡ä»¶å¤§å°å¤§äº0ï¼‰
                if os.path.exists(temp_file_path) and os.path.getsize(temp_file_path) > 0:
                    logging.info(f"âœ… è§†é¢‘ä¸‹è½½å®Œæˆ: {title}")
                    return True
                else:
                    logging.error(f"âŒ ä¸‹è½½å®Œæˆä½†æ–‡ä»¶æ— æ•ˆ: {title}")
                    return False
            else:
                logging.error(f"âŒ ffmpegä¸‹è½½å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}, è§†é¢‘: {title}")
                logging.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")
                return False

        except subprocess.TimeoutExpired:
            logging.error(f"â° ffmpegä¸‹è½½è¶…æ—¶: {title}")
            return False

        except Exception as e:
            logging.error(f"âŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {title}, é”™è¯¯: {e}")
            return False

    def generate_unique_filename(self, dir_path, title, file_ext):
        """
        ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶åï¼Œå¦‚æœå·²å­˜åœ¨åŒåæ–‡ä»¶ï¼Œåœ¨æ–‡ä»¶ååæ·»åŠ é€’å¢æ•°å­—
        """
        # æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ä¸åˆæ³•å­—ç¬¦
        cleaned_title = self.clean_filename(title)
        base_filename = f"{cleaned_title}{file_ext}"

        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›åŸå§‹æ–‡ä»¶å
        if not os.path.exists(os.path.join(dir_path, base_filename)):
            return base_filename

        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ é€’å¢æ•°å­—
        counter = 1
        while True:
            new_filename = f"{cleaned_title}_{counter}{file_ext}"
            if not os.path.exists(os.path.join(dir_path, new_filename)):
                logging.info(f"æ–‡ä»¶ {base_filename} å·²å­˜åœ¨ï¼Œä½¿ç”¨æ–°æ–‡ä»¶å: {new_filename}")
                return new_filename
            counter += 1

    def clean_filename(self, filename):
        """
        æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤æˆ–æ›¿æ¢ä¸åˆæ³•å­—ç¬¦
        """
        # å®šä¹‰ä¸åˆæ³•å­—ç¬¦
        illegal_chars = ['<', '>', ':', '"', '/', '\\', '|', '?', '*']

        cleaned = filename
        for char in illegal_chars:
            cleaned = cleaned.replace(char, '_')

        # ç§»é™¤é¦–å°¾ç©ºæ ¼å’Œç‚¹
        cleaned = cleaned.strip(' .')

        return cleaned

    def get_directory_path(self, item):
        """
        è¿”å›è§†é¢‘æ–‡ä»¶çš„å­˜å‚¨ç›®å½•è·¯å¾„
        """
        dir_path = os.path.join(self.videos_store, item.get('site', 'default'))
        return dir_path

    def cleanup_temp_files(self):
        """
        æ¸…ç†å­¤ç«‹çš„ä¸´æ—¶æ–‡ä»¶ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰
        """
        try:
            if not os.path.exists(self.temp_store):
                return

            temp_files = [f for f in os.listdir(self.temp_store) if f.endswith('.tmp.mp4')]

            # æ£€æŸ¥ä¸´æ—¶æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´ï¼Œåˆ é™¤è¶…è¿‡7å¤©çš„æ–‡ä»¶
            current_time = time.time()
            week_ago = current_time - (7 * 24 * 60 * 60)  # 7å¤©å‰

            cleaned_count = 0
            for temp_file in temp_files:
                temp_file_path = os.path.join(self.temp_store, temp_file)
                try:
                    file_mtime = os.path.getmtime(temp_file_path)
                    if file_mtime < week_ago:
                        os.remove(temp_file_path)
                        cleaned_count += 1
                        logging.info(f"åˆ é™¤è¿‡æœŸä¸´æ—¶æ–‡ä»¶: {temp_file}")
                except Exception as e:
                    logging.error(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ {temp_file}: {e}")

            if cleaned_count > 0:
                logging.info(f"æ¸…ç†äº† {cleaned_count} ä¸ªè¿‡æœŸä¸´æ—¶æ–‡ä»¶")

        except Exception as e:
            logging.error(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    def get_download_status(self):
        """
        è·å–ä¸‹è½½çŠ¶æ€ç»Ÿè®¡
        """
        stats = self.db.get_download_statistics()
        temp_files_count = 0

        if os.path.exists(self.temp_store):
            temp_files_count = len([f for f in os.listdir(self.temp_store) if f.endswith('.tmp.mp4')])

        stats['temp_files'] = temp_files_count
        stats['active_downloads'] = self.active_downloads

        return stats

    def close_spider(self, spider):
        """
        çˆ¬è™«å…³é—­æ—¶ç­‰å¾…æ‰€æœ‰ä¸‹è½½ä»»åŠ¡å®Œæˆå†å…³é—­
        """
        logging.info("ğŸ”„ çˆ¬è™«å³å°†å…³é—­ï¼Œç­‰å¾…æ‰€æœ‰M3U8ä¸‹è½½ä»»åŠ¡å®Œæˆ...")

        # æ˜¾ç¤ºå½“å‰ä¸‹è½½çŠ¶æ€
        status = self.get_download_status()
        logging.info(f"ğŸ“Š ä¸‹è½½çŠ¶æ€ç»Ÿè®¡: {status}")

        with self.lock:
            # æ ‡è®°ä¸ºå·²é€šçŸ¥å…³é—­
            self.shutdown_notified = True

            # å¦‚æœæ²¡æœ‰æ´»åŠ¨ä¸‹è½½ï¼Œç›´æ¥å…³é—­
            if self.active_downloads == 0:
                logging.info("âœ… æ²¡æœ‰æ´»åŠ¨çš„ä¸‹è½½ä»»åŠ¡ï¼Œç›´æ¥å…³é—­çˆ¬è™«")
                self._cleanup_resources()
                return

            logging.info(f"â³ ç­‰å¾… {self.active_downloads} ä¸ªä¸‹è½½ä»»åŠ¡å®Œæˆ...")

        # ç­‰å¾…æ‰€æœ‰ä¸‹è½½å®Œæˆ
        with self.downloads_done:
            # è®¾ç½®æœ€é•¿ç­‰å¾…æ—¶é—´ï¼Œé˜²æ­¢æ— é™ç­‰å¾…
            self.downloads_done.wait(timeout=7200)  # æœ€å¤šç­‰å¾…2å°æ—¶

        # æ¸…ç†å­¤ç«‹çš„ä¸´æ—¶æ–‡ä»¶
        self.cleanup_temp_files()

        self._cleanup_resources()

        # æœ€ç»ˆçŠ¶æ€ç»Ÿè®¡
        final_status = self.get_download_status()
        logging.info(f"ğŸ“Š æœ€ç»ˆä¸‹è½½çŠ¶æ€: {final_status}")
        logging.info("ğŸ‰ æ‰€æœ‰M3U8ä¸‹è½½ä»»åŠ¡å·²å®Œæˆï¼Œçˆ¬è™«å¯ä»¥å®‰å…¨å…³é—­")

    def _cleanup_resources(self):
        """
        æ¸…ç†èµ„æº
        """
        try:
            # å…³é—­æ•°æ®åº“è¿æ¥
            if hasattr(self, 'db'):
                self.db.close()
                logging.info("ğŸ—„ï¸ æ•°æ®åº“è¿æ¥å·²å…³é—­")

            # å…³é—­çº¿ç¨‹æ± 
            if hasattr(self, 'download_executor'):
                self.download_executor.shutdown(wait=False)
                logging.info("ğŸ§¹ ä¸‹è½½çº¿ç¨‹æ± å·²å…³é—­")

        except Exception as e:
            logging.error(f"âŒ å…³é—­èµ„æºæ—¶å‡ºé”™: {e}")
