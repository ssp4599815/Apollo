#!/usr/bin/env python
# -*-coding:utf-8 -*-
import json
import logging
import os
import shelve

import scrapy
from scrapy import Request, Selector

from ..items import VideoItem


class ChiguaSpider(scrapy.Spider):
    name = "51chigua"
    allowed_domains = ["beer.ggkpznuh.cc"]

    def __init__(self, *args, **kwargs):
        super(ChiguaSpider, self).__init__(*args, **kwargs)
        # æ‰“å¼€ä¸€ä¸ªshelveæ•°æ®åº“å­˜å‚¨å·²ç»è®¿é—®è¿‡çš„URL
        if not os.path.exists("./temp"):
            os.makedirs("./temp")
        self.visited_urls_db = shelve.open("./temp/visited_51chigua_urls")

    def start_requests(self):
        for page in range(1, 5):
            yield Request(url=f'https://beer.ggkpznuh.cc/search/%E8%90%9D%E8%8E%89/{page}/')
            #yield Request(
            #    url=f'https://beer.ggkpznuh.cc/tag/%E6%9D%8E%E6%AC%A3%E6%97%B6%E7%BA%A6%E7%82%AE%E5%AE%99%E6%96%AFZeus/')

    def parse(self, response):
        sel = Selector(response)
        chigua_titles = sel.xpath("//h2[@class='post-card-title' and @itemprop='headline']/text()").extract()
        chigua_hrefs = sel.xpath("//div[@id='archive']//a/@href").extract()

        for title, href in zip(chigua_titles, chigua_hrefs):
            item = VideoItem()
            item['title'] = title.strip()
            item['site'] = '51chigua'

            if "search" in href:
                continue

            complete_url = response.urljoin(href)  # Combining base url with href

            # æ£€æŸ¥æ¥å£æ˜¯å¦å·²ç»è¢«è®¿é—®è¿‡
            if complete_url in self.visited_urls_db:
                logging.info(f"Skipping {complete_url}, already visited.")
                continue
            self.visited_urls_db[complete_url] = True  # Mark the URL as visited

            logging.info("Requesting URL: %s" % complete_url)
            item['href'] = complete_url
            yield Request(url=complete_url, callback=self.parse_details, meta={'item': item})

    def parse_details(self, response):
        """
        è§£æè¯¦æƒ…é¡µé¢ï¼Œæå–m3u8é“¾æ¥å¹¶ç›´æ¥yieldç»™pipelineå¤„ç†
        """
        item = response.meta['item']
        
        # æå–è§†é¢‘é…ç½®æ•°æ®
        src_links = response.xpath("//div[@class='dplayer']/@data-config").extract()
        m3u8_found = False
        
        if src_links:
            for src in src_links:
                try:
                    config_data = json.loads(src)
                    video_url = config_data.get('video', {}).get('url', '')
                    
                    if video_url:
                        # æ£€æŸ¥æ˜¯å¦ä¸ºm3u8æ ¼å¼çš„è§†é¢‘
                        if video_url.endswith('.m3u8') or 'm3u8' in video_url:
                            logging.info(f"âœ… æ‰¾åˆ°M3U8è§†é¢‘é“¾æ¥: {video_url}")
                            item['m3u8_url'] = video_url
                            m3u8_found = True
                            
                            # ç›´æ¥yieldç»™pipelineå¤„ç†
                            logging.info(f"ğŸ¯ å‡†å¤‡å‘é€itemåˆ°pipeline: {item['title']}")
                            yield item
                            break  # æ‰¾åˆ°m3u8é“¾æ¥åç›´æ¥è·³å‡ºå¾ªç¯
                            
                        else:
                            # å¦‚æœä¸æ˜¯m3u8æ ¼å¼ï¼Œä½†ä»ç„¶æ˜¯è§†é¢‘é“¾æ¥
                            logging.info(f"æ‰¾åˆ°å…¶ä»–æ ¼å¼è§†é¢‘é“¾æ¥: {video_url}")
                            if 'm3u8_url' not in item:
                                item['m3u8_url'] = []
                            item['m3u8_url'].append(video_url)
                            yield item
                            
                except json.JSONDecodeError as e:
                    logging.error(f"è§£æè§†é¢‘é…ç½®JSONå¤±è´¥: {e}")
                    continue
        
        if not m3u8_found:
            logging.info("é¡µé¢ä¸Šæœªæ‰¾åˆ°è§†é¢‘é…ç½®æ•°æ®ï¼Œå°è¯•å…¶ä»–æ–¹å¼...")
            
            # å°è¯•å…¶ä»–å¯èƒ½çš„è§†é¢‘é“¾æ¥æå–æ–¹å¼
            # æŸ¥æ‰¾å¯èƒ½çš„m3u8é“¾æ¥
            m3u8_links = response.xpath("//source[@src[contains(., '.m3u8')]]/@src").extract()
            if not m3u8_links:
                # åœ¨è„šæœ¬æˆ–å…¶ä»–åœ°æ–¹æŸ¥æ‰¾m3u8é“¾æ¥
                m3u8_links = response.re(r'["\']([^"\']*\.m3u8[^"\']*)["\']')
            
            if m3u8_links:
                for m3u8_link in m3u8_links:
                    # ç¡®ä¿URLæ˜¯å®Œæ•´çš„
                    if m3u8_link.startswith('http'):
                        video_url = m3u8_link
                    else:
                        video_url = response.urljoin(m3u8_link)
                    
                    logging.info(f"âœ… é€šè¿‡å…¶ä»–æ–¹å¼æ‰¾åˆ°M3U8é“¾æ¥: {video_url}")
                    item['m3u8_url'] = video_url
                    
                    # ç›´æ¥yieldç»™pipelineå¤„ç†
                    logging.info(f"ğŸ¯ å‡†å¤‡å‘é€itemåˆ°pipeline: {item['title']}")
                    yield item
                    break  # åªå–ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„m3u8é“¾æ¥
            else:
                logging.warning(f"âŒ æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘é“¾æ¥: {item['title']}")

    def closed(self, reason):
        # å½“çˆ¬è™«å…³é—­æ—¶ï¼Œç¡®ä¿æˆ‘ä»¬ä¹Ÿå…³é—­äº†shelveæ•°æ®åº“
        self.visited_urls_db.close()
        logging.info(f"çˆ¬è™«å…³é—­ï¼ŒåŸå› : {reason}")
